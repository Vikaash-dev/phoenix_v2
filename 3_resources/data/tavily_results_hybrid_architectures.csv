url,title,content,score,raw_content
https://www.explorationpub.com/Journals/em/Article/1001377,Comparative analysis of transformer architectures for brain tumor ...,"In parallel, the task of brain tumor segmentation has witnessed rapid innovation through the integration of Transformers into U-shaped architectures, as researchers aim to combine the hierarchical feature extraction power of CNN encoders with the global dependency modeling of Transformers. Zhang et al. [35)] proposed AugTransU-Net, which enriches bottleneck representations through Augmented Transformer modules with circulant projections, thereby enhancing feature diversity at deeper layers. Extending this concept further, Zhang et al. [36)] introduced ETUnet, an enhanced U-Net that fuses CNN-Transformer hybrids in the encoder, incorporates spatial-channel attention in the bottleneck to optimize global interactions, and integrates cross-attention mechanisms into skip connections to refine [...] Recent advancements in medical image analysis have increasingly highlighted the limitations of traditional CNNs in modeling long-range dependencies, paving the way for the adoption of Transformer-based architectures. Within the domain of brain tumor classification, a variety of studies have explored this paradigm shift by introducing innovative hybrid models and optimization strategies. Goceri [32)] developed a CNN-Transformer hybrid framework that effectively balances local texture extraction with global contextual modeling, achieving strong performance in both glioma grading and multi-class tumor recognition. In a similar vein, Tanone et al. [33)] investigated feature optimization pipelines grounded in ViTs. Tanoneʼs ViT-CB framework employed principal component analysis (PCA) for [...] Unlike studies that focus on a single novel architecture or hybrid model, we systematically evaluate eleven models from three foundational Transformer families (ViT, DeiT, and Swin) across four distinct architectural scales (ʻtinyʼ, ʻsmallʼ, ʻbaseʼ, and ʻlargeʼ). This broad-spectrum analysis offers a panoramic view of the current landscape, allowing for direct and standardized comparisons of their capabilities on a unified task.",0.9999858,
https://www.nature.com/articles/s41598-025-09833-y,A novel hybrid vision UNet architecture for brain tumor segmentation ...,"A hybrid transformer-enhanced convolutional neural network (TECNN) model for brain tumor classification that combines CNNs for local feature extraction with Transformers to capture global context31.""). A Feature Fusion Module (FFM) and an Intelligent Merge Module (IMM) were employed to bridge the gap between CNN and Transformer representations, enhancing feature integration. The model also utilizes channel-wise attention and adaptive pooling to retain class-specific information, achieving high accuracy on the BraTS 2018 and Figshare datasets. [...] Inspired by Transformer models’ success in natural language processing, Vision Transformers are a kind of deep learning model for computer vision applications. In the proposed HVU architecture, ViT is incorporated to enhance the global representation capability, complementing the local feature extraction strengths of convolutional neural networks (CNNs). As illustrated in Fig. 10, the ViT architecture leverages self-attention mechanisms to model relationships between different regions of an image. The input image is divided into fixed-size patches of 16\(\times\)16 pixels. A stride of 16 is applied to avoid overlapping, ensuring non-redundant spatial coverage. Each image patch is then flattened into a 1D vector and linearly projected into a lower-dimensional embedding space through a [...] ArXiv:2103.04430
                  
                 [cs].""). These models improve feature extraction and fusion through the use of transformers and CNNs, leading to more accurate segmentations. To segment brain tumors from 3D MRI data, TransUNet uses a transformer along with a U-Net, whereas TransBTS uses a transformer along with a 3D CNN. In TransBTS, the encoder uses 3D CNN to extract spatial features. The decoder creates a better segmentation map by applying transformer features. The transformer in TransBTS models the global context, which helps the decoder segment data more effectively.",0.9999778,
https://pmc.ncbi.nlm.nih.gov/articles/PMC12699001/,Hybrid Deep Learning for Brain Tumor Detection - PubMed Central,"### Transformer-Based and Attention Models [...] Transformer-based models have appeared in the field of medical image analysis as an alternative to the traditional CNNs in recent years and have proven their efficiency. The Swin Transformer stands out among them and brings the hierarchical structure with shifted windows that allow the efficient representation of long-range dependencies, but retain the computational efficiency. TransUNet uses transformer decoders together with CNN-based encoders and has the benefit of both local feature extraction and global context modeling, which is especially handy in segmenting and detecting tumor boundaries. The models have proved to be of high quality toward the characterization of irregular tumor shapes and handling of multi-scale data when applying brain MRI. Further, MedViT (Medical Vision [...] A method to classify brain tumors has been extended to utilize 3D MRI data besides the slices of a typical MRI. The authors in Jyothi and Singh 24  proposed a 3-dimensional convolutional neural network (CNN) for automatically grading gliomas, from multi-sequence MRI using regions of interest (ROI). This work demonstrated that 3D CNNs can be used to learn spatial and volumetric features from MRI data with 89.5% accuracy for glioma grading and 92.98% in the prediction of tumor regions. Provided a 3D whole-slice method with DenseNet as a feature extractor for each planar view from the raw (stacked) image in Lu et al. 25  Then, in the case of classification, a Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) Units was used. This hybrid 2D to 3D approach demonstrates that the",0.99997294,
https://www.nature.com/articles/s41598-025-04591-3,Optimized deep learning for brain tumor detection: a hybrid ... - Nature,"Sara Tehsin et al.23, 89. 
                  
                  
                 (2025)."") proposed GATransformer, a novel transformer architecture built upon a Graph Attention Network (GAT) to enhance explainability in brain tumor detection (BTD). It makes an integration of attention mechanism, GAT, and transformers, in order to extracting deeper features and improving model representation. It offers interpretable attention maps that expose certain tumor regions, aiding clinical understanding. GATransformer achieved high classification accuracy on FigShare, Kaggle, BraTS2019 and BraTS2020 datasets by also improving model transparency. [...] Structural characteristics of CNNs were considered as well as their use in various medical domains, and how transfer learning helps with performance in small-data conditions was discussed. Their results lend support for the growing use of hybrid architectures, and context-specific pre-trained models to enhance clinical decision making and diagnostic accuracy. [...] .""). We use a VGG16 backbone and a Custom Attention (CA) layer that employs SoftMax-weighted attention to dynamically weigh tumor-specific features. This design takes advantage of the strengths of transfer learning where a network trained previously on a rich image domain can be repurposed to a narrowly-defined medical task, and enhances feature representation through attention. Our model is capable of highlighting clinically relevant areas, unlike regular CNNs, which pay equal attention to all features in the image. We further improve interpretability by using Grad-CAM visualizations to produce the heatmaps that show which parts of the image were most responsible for each prediction.",0.9999443,
https://pmc.ncbi.nlm.nih.gov/articles/PMC12092918/,Deep Learning Approaches for Brain Tumor Detection and ...,"navigate through these limitations, the transition to the transformative role of transformers in addressing these challenges becomes evident. Transformers, with their attention mechanisms and ability to capture complex relationships in data, represent a compelling shift in paradigm for enhancing the accuracy and efficiency of brain tumor detection models. [...] #### Transformers and Attention Mechanism [...] The transformer architecture features attention mechanisms as a crucial component. Over recent years, attention mechanisms have gained rapid prominence in computer vision. Notably, Jun et al. identified limitations in CNNs for pinpointing the focal point of a lesion . In their work, they proposed a novel brain tumor classification method based on an attention mechanism and a multipath network to address this challenge. The dataset comprises T1-weighted post-contrast brain images from Figshare, encompassing three types of tumor images: gliomas, meningiomas, and pituitary adenomas. The dataset includes 3064 image slices of size 512x512, expanded to 9192 images through data augmentation methods. The attention mechanism selectively extracts critical information related to the target region",0.999943,
https://www.sciencedirect.com/science/article/abs/pii/S0010482525008662,BioTransX: A novel bi-former based hybrid model with bi-level ...,"The primary contributions of this study are as follows:

 1.

  We propose a novel hybrid CNN–Transformer architecture that effectively combines the local feature extraction capabilities of CNNs with the global context modeling strength of transformers, resulting in significantly improved performance for brain tumor classification.
 2.

  We develop a robust feature-level ensemble approach, integrating DenseNet169, ResNet50, and Xception. The fused features are passed to a transformer module, which captures long-range dependencies and enhances classification robustness.
 3. [...] ## Conclusion

In this work, we introduced BioTransX, a hybrid deep learning framework that integrates Convolutional Neural Networks (CNNs) with a Bi-level Routing Attention-based Lightweight Transformer to improve brain tumor classification. By combining the strengths of CNNs in local feature extraction and transformers in modeling global contextual relationships, our model aims to deliver higher accuracy, interpretability, and efficiency compared to traditional approaches. The BioTransX framework

## CRediT authorship contribution statement [...] ## Discussion

This study aimed to improve the performance of brain tumor classification by introducing a novel hybrid framework that integrates Convolutional Neural Networks (CNNs) with a Bi-level Routing Attention-based Lightweight Transformer (BioTransX). Our findings demonstrate that the hybrid framework outperforms traditional deep learning methods, not only in terms of classification accuracy but also in interpretability and computational efficiency, which are critical factors in medical applications.

## Conclusion",0.99993074,
https://www.medrxiv.org/content/10.1101/2025.10.14.25338038v1.full-text,An Explainable Hybrid CNN–Transformer Framework with Aquila ...,"Gull et al. (16; 27) proposed dual-path CNN-Transformer hybrids where CNN features were fed alongside transformer token outputs into a late fusion classifier.

Sharma et al. (28) applied parallel attention streams to CNN-encoded blocks, improving classification of low-contrast tumor regions. Ayomide et al. (29) demonstrated increased F1-scores when combining hierarchical CNN outputs with cross-layer attention mechanisms from transformers.

Phan et al. (25) compared serial and parallel hybrid designs, concluding that early fusion of CNN and transformer features often led to overfitting on small datasets, whereas late fusion preserved independence and improved generalization.

Fig 3.
Architecture of a hybrid CNN-Transformer model for brain tumor classification. [...] The performance of the proposed hybrid CNN-Transformer-AQO model was benchmarked against various state-of-the-art deep learning architectures commonly employed for brain tumor classification, including VGG19, ResNet50, and ViT-B/16. The results of this evaluation, as summarized in Table 5, clearly indicate that the proposed model achieves superior classification performance across all key metrics.

View this table:
   View inline
   View popup
   Download powerpoint

Table 5.Performance comparison of proposed and baseline models. [...] This section details the mathematical modeling underlying the hybrid CNN-Transformer architecture used for brain tumor classification. The formulation encompasses spatial feature extraction via convolutional neural networks, global context modeling via transformer-based attention mechanisms, and their fusion using a learnable interpolation mechanism.

#### 1. Input Representation and CNN Feature Extraction

Let the input MRI image be represented as a 3D tensor: Image 27: Embedded Image where _H_ and _W_ denote the height and width of the image, respectively, and _C_ represents the number of channels (e.g., _C_ = 1 for grayscale images).",0.99992037,
https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1508451/full,A novel approach for the detection of brain tumor and its ... - Frontiers,"The Vision Transformers are able to capture various global and diverse relations without the need for bias training, which is very beneficial for them. However, it can also be very expensive to obtain the necessary data. The ability of vision transformers to overcome various image distortions, such as permutations and adversarial patches, is a remarkable achievement. In spite of that, choosing the right architecture for a Computer Vision task is not always the best choice. Hybrid architectures, which combine the features of Vision Transformers and convolutional layers, are often successful. Table 2 shows the architecture layer used in our proposed model prediction.

Table 2

Table 2. Architecture layer used in our proposed model prediction. [...] are fed into the transformer. A transformer encoder then processes the embedded and input sequences. A Multilayer Perceptron (MLP) can be used to train the transformer. Multilayered perceptron heads can be used to create new learning patches for the final classification. The positions and embedded patches are then fed into the transformer. It features multi-headed Multilayer Perceptron(MLP) blocks and self-attention in Figure 3. [...] The Vision Transformers and CNNs have their own architectural differences. CNNs can still achieve remarkable results even when using training data that is not as large as what Vision Transformers require. The CNNs’ inclusion of certain inductive biases may explain the difference between their behavior and that of the Vision Transformers. On the one hand, these networks tend to limit the scope of the analysis they provide, making it more difficult to grasp global relations.",0.9998969,
https://arxiv.org/pdf/2508.17128?,[PDF] CE-RS-SBCIT: A Novel Channel-Enhanced Hybrid CNN - arXiv,"F1-score, and 98.43% precision. These results underscore the potential of CE-RS-SBCIT as a robust diagnostic framework that bridges CNN and transformer paradigms for reliable and efficient brain tumor analysis. Keywords: Brain tumors, Deep Learning, Transformers, Boundary, Homogeneous, Spatial, Residual Learning, CNN. 2 1. Introduction The brain, the body’s most complex and vital organ that regulates the nervous system, can develop brain tumors (BTs) from abnormal and uncontrolled cell growth. BTs are among the deadliest malignancies and the most common type of cancer worldwide, according to statistics from Global Cancer Statistics . In modern clinical imaging, early detection and classification of BTs are critical research priorities because they directly affect patient survival and the [...] extensive evaluation across diverse datasets demonstrates strong generalization, highlighting the model’s potential for deployment in clinical decision support systems. 32 6. Conclusion This study introduces a hybrid diagnostic framework, CE-RS-SBCIT, that integrates convolutional and transformer paradigms for automated brain tumor classification from MRI scans. The design systematically addresses clinical challenges such as subtle contrast shifts, morphological heterogeneity, and textural ambiguity by combining local features encoding with global dependency modeling. At the initial stage, a STEM convolution extracts locally correlated features and forwards them for transformer tokenization, ensuring efficient local-to-global alignment and reduced computational complexity. The customized [...] precision, F1-score, and AUC (Table 3). The multi-class classification task involved categorizing MRI scans into meningioma, glioma, pituitary, and 22 normal classes. The SBCIT backbone outperformed competing models, attaining 96.8% accuracy, 96.7% sensitivity, 96.4% precision, and a 96.55% F1-score, thereby demonstrating its superior discriminative capability in brain tumor diagnosis. Integrating CNNs with transformers in the architecture significantly enhanced performance on the challenging dataset. In addition, the CE-RS-SBCIT technique outperformed existing ViTs/CNNs, achieving an accuracy of 98.3%, sensitivity of 98.43%, precision of 98.08%, and an F1-score of 98.25%. Additionally, it attained remarkable PR-AUC (0.9875) and ROC-AUC (0.9894) scores. The outcomes confirmed the efficacy",0.99988675,
https://www.sciencedirect.com/science/article/pii/S1746809425011474,Enhancing brain tumor classification with a novel attention based ...,"this study, we propose a novel attention-based, explainable DL framework designed to improve the performance and transparency of brain tumor diagnosis. We introduce the Strip-Style Pooling Attention Network (SSPANet), which combines the strengths of channel and spatial attention mechanisms to more effectively capture intricate imaging features. We evaluated SSPANet using VGG16 and ResNet50 as backbone architectures, integrating it alongside existing attention methods for comparison. Among all configurations, ResNet50 combined with SSPANet achieves the best results, with 97% accuracy, precision, recall, and F1-score, along with 95% Cohen’s Kappa and Matthews Correlation Coefficient. For interpretability, we employ GradCAM, GradCAM++, and EigenGradCAM across attention-guided DL models. The [...] and EigenGradCAM across attention-guided DL models. The ResNet50 + SSPANet + GradCAM++ combination consistently provides superior visual explanations, highlighting SSPANet’s ability to capture complex spatial-contextual information effectively. We also offer a theoretical analysis to support the efficiency and effectiveness of the proposed attention mechanism. [...] Accurate and early detection of brain tumors is essential for effective treatment planning in medical diagnosis. However, deep learning (DL) models often struggle with MRI-based tumor detection due to significant variability in tumor size, shape, and location. Traditional diagnostic techniques are limited by subjectivity and low interpretability, while many DL models operate as black boxes, reducing clinical trust. Incorporating attention mechanisms can help by directing the model’s focus to the most informative regions of an image, thus improving both accuracy and interpretability. However, existing attention methods often fail to capture the complex spatial and contextual features present in medical images such as MRI scans. In this study, we propose a novel attention-based, explainable",0.999826,
https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2025.1702902/full,GAME-Net: an ensemble deep learning framework integrating ...,"where F′ denotes extracted features, W are learnable weights, and b is the bias term. Attention gates are embedded in the decoder stage of U-Net to suppress irrelevant activations and enhance focus on tumor-specific regions.

A CNN-based classifier further discriminates tumor from non-tumor regions, using:

where Wconv are convolutional kernels, \ is the convolution operator, and σ is the ReLU activation function. Classification probabilities are obtained using:

where Xi is the logit for class i, and C is the total number of classes.

A Transformer-based self-attention module refines feature representation via:

where Q, K, and V denote query, key, and value matrices, and dk is a scaling factor. [...] These results confirm that the proposed GAME-based ensemble surpasses conventional U-Net, ResNet-50, and Transformer hybrids in both segmentation accuracy and classification robustness. The generative autoencoder with integrated attention significantly improved tumor discrimination and reduced misclassification. Each architectural component provides a measurable benefit: Generative Autoencoder pretraining improves feature separability and increases Dice score relative to plain U-Net; attention mechanisms reduce boundary ambiguity and improve Jaccard Index; the CNN classifier lowers false positives by bypassing segmentation for negative cases; and latent k-means clustering reduces spurious predictions while improving computational efficiency. Compared with TransUNet and Swin-UNet, the [...] Recent advances in AI and deep learning (DL) have enabled significant progress in automated brain tumor segmentation, improving both precision and efficiency (LeCun et al., 2015; Azad et al., 2024). Deep learning models such as Convolutional Neural Networks (CNNs) (LeCun et al., 2015) and U-Net-based architectures (Azad et al., 2024) have set new benchmarks for segmentation accuracy. Further improvements have emerged through advanced architectures, including 3D U-Net (Çiçek et al., 2016), Attention U-Net (Zhang et al., 2024), and Transformer-based networks (Nguyen et al., 2024), each designed to address complex spatial and contextual dependencies in MRI data. Despite these achievements, challenges persist, such as class imbalance in tumor and background pixels, increased computational",0.9997063,
https://pmc.ncbi.nlm.nih.gov/articles/PMC10453020/,Brain Tumor Detection Based on Deep Learning Approaches and ...,"We developed a fully automated brain tumor detection model using deep learning algorithms and YOLOv7. This model aims to reduce false detections and ultimately minimize the loss of human lives associated with brain tumors.

After evaluating the effects of three different attention mechanisms on the model’s output, we decided to adopt the CBAM (Convolutional Block Attention Module) module. The decoupled head and CBAM attention mechanism have been verified to be successful in enhancing the performance of the brain tumor detection model. [...] ### 3.5. Attention Mechanism Module [...] The CBAM component is a fully fledged attention mechanism, successfully capturing the spatial and channel dimensions of input data. The CBAM’s Channel Attention Module (CAM) and Spatial Attention Module (SAM) are depicted in Figure 5. The CAM’s function is to bring attention to important details and regions in the channel dimension, such as the foreground and other focal points of the image. The SAM, on the other hand, is made to pinpoint where in an image crucial contextual details are located for a full picture understanding. The CBAM module, which combines the CAM and SAM, is better able to concurrently capture local and global attention, allowing the network to zero down on important spatial and channel properties. CBAM is a modular approach that can be easily integrated into various",0.99963737,
https://arxiv.org/abs/2401.00587,[2401.00587] Brain Tumor Segmentation Based on Deep Learning ...,"View PDF [...] aggressive data augmentations and deeper neural networks. Following the preprocessing of the MRI modalities, a fully convolutional autoencoder with soft attention segments the different brain MRIs. When these deep learning algorithms are implemented in practice, analysts and physicians cannot differentiate between accurate and inaccurate predictions. Subsequently, test time augmentations and an energy-based model were used for voxel-based uncertainty predictions. Experimentation was conducted on the BraTS benchmarks and achieved state-of-the-art segmentation performance. Additionally, qualitative results were used to assess the segmentation models and uncertainty predictions. [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate

> eess > arXiv:2401.00587

# Electrical Engineering and Systems Science > Image and Video Processing

arXiv:2401.00587 (eess)

Submitted on 31 Dec 2023 ([v1), last revised 14 Mar 2024 (this version, v2)]

# Title:Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms, and Energy-Based Uncertainty Prediction

Authors:Zachary Schwehr, Sriman Achanta

View a PDF of the paper titled Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms, and Energy-Based Uncertainty Prediction, by Zachary Schwehr and Sriman Achanta",0.99440175,
https://www.sciencedirect.com/science/article/pii/S2666307425000567,A Novel Hybrid Res2Net-UNet Model for Accurate Brain Tumor ...,"Elsevier logo
Society Logo

## International Journal of Cognitive Computing in Engineering

International Journal of Cognitive Computing in Engineering

# A novel hybrid Res2Net-UNet model for accurate brain tumor segmentation in MRI

## Highlights

## Abstract

## Keywords

## Cited by (0)

## Recommended articles

Elsevier logo with wordmark

All content on this site: Copyright © 2026 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.

RELX group home page",0.9161096,
